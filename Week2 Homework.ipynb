{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "804f902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words following 'AVATAR' sorted by frequency:\n",
      "'State': 67,\n",
      "'is': 41,\n",
      "'Roku': 33,\n",
      "'and': 29,\n",
      "'\n",
      "SCENEDESCRIPTION': 19,\n",
      "'Aang': 16,\n",
      "'has': 14,\n",
      "'\n",
      "AANG': 11,\n",
      "'Kyoshi': 11,\n",
      "'\n",
      "SOKKA': 11,\n",
      "'I': 11,\n",
      "'to': 9,\n",
      "'will': 7,\n",
      "'\n",
      "ZUKO': 7,\n",
      "'before': 6,\n",
      "'': 6,\n",
      "'who': 6,\n",
      "'Day': 6,\n",
      "'players': 6,\n",
      "'was': 5,\n",
      "'would': 5,\n",
      "'You': 5,\n",
      "'Rokus': 5,\n",
      "'looks': 5,\n",
      "'\n",
      "KATARA': 4,\n",
      "'for': 4,\n",
      "'but': 4,\n",
      "'stuff': 4,\n",
      "'He': 4,\n",
      "'Kuruk': 4,\n",
      "'Yangchen': 4,\n",
      "'Cut': 4,\n",
      "'\n",
      "AZULA': 4,\n",
      "'looking': 4,\n",
      "'World': 3,\n",
      "'thing': 3,\n",
      "'But': 3,\n",
      "'Spirit': 3,\n",
      "'\n",
      "IROH': 3,\n",
      "'standing': 3,\n",
      "'can': 3,\n",
      "'The': 3,\n",
      "'with': 3,\n",
      "'walking': 3,\n",
      "'look': 3,\n",
      "'from': 3,\n",
      "'we': 3,\n",
      "'in': 2,\n",
      "'himself': 2,\n",
      "'stands': 2,\n",
      "'If': 2,\n",
      "'My': 2,\n",
      "'on': 2,\n",
      "'huh': 2,\n",
      "'Turns': 2,\n",
      "'Sokka': 2,\n",
      "'its': 2,\n",
      "'must': 2,\n",
      "'it': 2,\n",
      "'Thats': 2,\n",
      "'Its': 2,\n",
      "'youre': 2,\n",
      "'Who': 2,\n",
      "'powers': 2,\n",
      "'We': 2,\n",
      "'walks': 2,\n",
      "'Now': 2,\n",
      "'sleeping': 2,\n",
      "'so': 2,\n",
      "'reaches': 2,\n",
      "'Points': 2,\n",
      "'cheers': 2,\n",
      "'journey': 2,\n",
      "'doesnt': 2,\n",
      "'are': 2,\n",
      "'line': 2,\n",
      "'kept': 1,\n",
      "'mastered': 1,\n",
      "'Helmsman': 1,\n",
      "'Zuko': 1,\n",
      "'master': 1,\n",
      "'an': 1,\n",
      "'Hes': 1,\n",
      "'races': 1,\n",
      "'going': 1,\n",
      "'died': 1,\n",
      "'probably': 1,\n",
      "'Cycle': 1,\n",
      "'dies': 1,\n",
      "'or': 1,\n",
      "'his': 1,\n",
      "'Slightly': 1,\n",
      "'alive': 1,\n",
      "'Camera': 1,\n",
      "'Doing': 1,\n",
      "'Frontal': 1,\n",
      "'Monk': 1,\n",
      "'child': 1,\n",
      "'\n",
      "SENLINVILLAGELEADER': 1,\n",
      "'speaking': 1,\n",
      "'returned': 1,\n",
      "'lately': 1,\n",
      "'Lowers': 1,\n",
      "'\n",
      "GREATFIRESAGE': 1,\n",
      "'contacts': 1,\n",
      "'When': 1,\n",
      "'\n",
      "SHYU': 1,\n",
      "'wont': 1,\n",
      "'Apparently': 1,\n",
      "'\n",
      "ZHAO': 1,\n",
      "'camping': 1,\n",
      "'Pan': 1,\n",
      "'Blushes': 1,\n",
      "'aint': 1,\n",
      "'disappeared': 1,\n",
      "'relics': 1,\n",
      "'\n",
      "GYATSO': 1,\n",
      "'Why': 1,\n",
      "'should': 1,\n",
      "'Only': 1,\n",
      "'gives': 1,\n",
      "'\n",
      "JEE': 1,\n",
      "'Master': 1,\n",
      "'Meng': 1,\n",
      "'snatching': 1,\n",
      "'you': 1,\n",
      "'held': 1,\n",
      "'Do': 1,\n",
      "'needs': 1,\n",
      "'Crowd': 1,\n",
      "'State\n",
      "Cut': 1,\n",
      "'Cuts': 1,\n",
      "'State\n",
      "He': 1,\n",
      "'Even': 1,\n",
      "'Stuff': 1,\n",
      "'Come': 1,\n",
      "'showed': 1,\n",
      "'Im': 1,\n",
      "'do': 1,\n",
      "'And': 1,\n",
      "'sir': 1,\n",
      "'gather': 1,\n",
      "'now': 1,\n",
      "'members': 1,\n",
      "'Get': 1,\n",
      "'all': 1,\n",
      "'Grabs': 1,\n",
      "'She': 1,\n",
      "'state': 1,\n",
      "'\n",
      "TICKETLADY': 1,\n",
      "'Take': 1,\n",
      "'Humbly': 1,\n",
      "'around': 1,\n",
      "'\n",
      "JOODEE': 1,\n",
      "'Surprised': 1,\n",
      "'accompanied': 1,\n",
      "'Sideview': 1,\n",
      "'a': 1,\n",
      "'Jumps': 1,\n",
      "'keeps': 1,\n",
      "'Longshot': 1,\n",
      "'Jet': 1,\n",
      "'youve': 1,\n",
      "'at': 1,\n",
      "'begins': 1,\n",
      "'completely': 1,\n",
      "'\n",
      "LONGFENG': 1,\n",
      "'becomes': 1,\n",
      "'arrives': 1,\n",
      "'\n",
      "KUEI': 1,\n",
      "'celebrates': 1,\n",
      "'This': 1,\n",
      "'Trying': 1,\n",
      "'forever': 1,\n",
      "'What': 1,\n",
      "'fell': 1,\n",
      "'Approaching': 1,\n",
      "'gets': 1,\n",
      "'follows': 1,\n",
      "'Lifts': 1,\n",
      "'packing': 1,\n",
      "'saved': 1,\n",
      "'groups': 1,\n",
      "'as': 1,\n",
      "'flying': 1,\n",
      "'descending': 1,\n",
      "'It': 1,\n",
      "'Unfortunately': 1,\n",
      "'eluded': 1,\n",
      "'holding': 1,\n",
      "'Promise': 1,\n",
      "'style': 1,\n",
      "'Stupid': 1,\n",
      "'\n",
      "HAKODA': 1,\n",
      "'comes': 1,\n",
      "'not': 1,\n",
      "'hasnt': 1,\n",
      "'\n",
      "TEO': 1,\n",
      "'maybe': 1,\n",
      "'firebending': 1,\n",
      "'make': 1,\n",
      "'turns': 1,\n",
      "'anymore': 1,\n",
      "'Maybe': 1,\n",
      "'Unsheathes': 1,\n",
      "'applauds': 1,\n",
      "'laughs': 1,\n",
      "'rises': 1,\n",
      "'His': 1,\n",
      "'\n",
      "TOPH': 1,\n",
      "'silly': 1,\n",
      "'appear': 1,\n",
      "'sitting': 1,\n",
      "'grimace': 1,\n",
      "'Stands': 1,\n",
      "'again': 1,\n",
      "'inside': 1,\n",
      "'myself': 1,\n",
      "'Puts': 1,\n",
      "'shares': 1,\n",
      "'runs': 1,\n",
      "'approaches': 1,\n",
      "'sans': 1,\n",
      "'\n",
      "JUNE': 1,\n",
      "'Okay': 1,\n",
      "'appears': 1,\n",
      "'spared': 1,\n",
      "'tea': 1,\n"
     ]
    }
   ],
   "source": [
    "#my preferred version of the Monty Hall problem\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re  # For regular expressions\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-08-11/avatar.csv\"\n",
    "avatar = pd.read_csv(url)\n",
    "\n",
    "# Create the list of words by combining character names and full text\n",
    "words = (\"\\n\" + avatar.character.str.upper().str.replace(' ', '.') + \": \" + avatar.full_text + \" \").sum().split(' ')\n",
    "\n",
    "# Define a function to remove punctuation from words (to normalize similar words)\n",
    "def clean_word(word):\n",
    "    return re.sub(r'[^\\w\\s]', '', word)  # Remove punctuation, keep alphanumeric and whitespace characters\n",
    "\n",
    "# Initialize the word usage and transition dictionaries\n",
    "word_used = defaultdict(int)  # Tracks how often each word occurs\n",
    "next_word = defaultdict(lambda: defaultdict(int))  # Nested defaultdict for transitions and their counts\n",
    "\n",
    "# Build the word occurrence and transition model\n",
    "for i, word in enumerate(words[:-1]):\n",
    "    clean_current_word = clean_word(word)\n",
    "    clean_next_word = clean_word(words[i+1])\n",
    "    \n",
    "    word_used[clean_current_word] += 1\n",
    "    \n",
    "    # The next word in the sequence\n",
    "    next_word[clean_current_word][clean_next_word] += 1  # Count the transition from `clean_current_word` to `clean_next_word`\n",
    "\n",
    "# Get all words that follow 'AVATAR' and sort them by frequency\n",
    "avatar_next_words = next_word['Avatar']\n",
    "sorted_avatar_next_words = sorted(avatar_next_words.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted word counts\n",
    "print(\"Words following 'AVATAR' sorted by frequency:\")\n",
    "for word, count in sorted_avatar_next_words:\n",
    "    print(f\"'{word}': {count},\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ce162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The conversation between ChatBox and me for Question3\n",
    "#https://chatgpt.com/c/66f0ce11-5a14-8001-bf81-4ddb07ae2e9d\n",
    "\n",
    "\n",
    "\n",
    "#Here's a summary of our conversation:\n",
    "#1. **Initial Code and Issue**: \n",
    "#   - You shared a code that creates a Markov model-like structure based on text from a dataset. The issue you \n",
    "#encountered was a `TypeError` when incrementing word transitions (`next_word[word][words[i+1]] += 1`).\n",
    "\n",
    "#2. **Fixing the `TypeError`**:\n",
    "#   - The error was due to `next_word[word]` being treated as an `int` instead of a nested dictionary. I helped \n",
    "#fix this by using a `defaultdict(lambda: defaultdict(int))`, ensuring that word transitions are counted properly.\n",
    "\n",
    "#3. **Grouping Words with Punctuation**:\n",
    "#   - You wanted to group words like `'Roku?'`, `'Roku!'`, and `'Roku;'` under `'Roku'`. I helped by introducing a\n",
    "#`clean_word()` function using regular expressions to remove punctuation, ensuring variations of the same word are \n",
    "#grouped.\n",
    "\n",
    "#4. **Sorting Word Counts**:\n",
    "#   - You asked how to sort word counts, such as `'will': 7, 'Helmsman': 1, 'is': 41`, to display them from most to\n",
    "#least frequent. I provided code to sort and print the word counts in descending order.\n",
    "\n",
    "#5. **Displaying Words Following a Specific Word**:\n",
    "#   - You asked how to display and sort all words following the word `'Avatar'`. I helped by extracting the words \n",
    "#that follow `'Avatar'` in the Markov model, sorting them by frequency, and printing the results.\n",
    "\n",
    "#Each step involved fixing issues or enhancing the Markov model to handle the dataset and output meaningful results\n",
    "#based on word transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question6:\n",
    "#ChatBots are really helpful, since it can quickly understand my questions and help me to solve it. Also, it can \n",
    "#read through and explain the programme for me, which helps me out and save my time to learning these programmes. \n",
    "#For the learning later on, I think I will still using chatbox for helping me to understand the codes since it can \n",
    "#save me time, although ChatBox might give a wrong answer, than I will going to ask it again with a different way.\n",
    "\n",
    "\n",
    "\n",
    "#Question7:\n",
    "#By having conversation these few days, I find out that ChatBox can do lots more than I thought before. I can write\n",
    "#code, if I gives it the directives and it can also help me to explain the error in the code and gave me some \n",
    "#solution to solve it. I predict that later on maybe we through data to ChatBox and tell them what result we need it\n",
    "#can code by it self and use different statistic mode and gives us the best result. Or even, it can shows the result\n",
    "#it runs out and analyze why other module is not good enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
